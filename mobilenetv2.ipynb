{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOBMwPpMFR087prYRxewHGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adenurchalisa/DeepLearning_finalproject/blob/main/mobilenetv2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGWC5Yk9f-fb",
        "outputId": "7a245368-0ae5-4ac5-ef46-767849a67391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import keras_tuner as kt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOk02u_ygXnI",
        "outputId": "bb0e8db7-6dfa-41bf-be7c-af87e75d5806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/DL/dataset/dataset_augmented\"\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "JmbrgJJ6gZuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMG_SIZE, IMG_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")\n",
        "NUM_CLASSES = train_gen.num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBrdaUHnghU0",
        "outputId": "0dad3ea6-be5a-411c-bb71-7d5880947e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 757 images belonging to 3 classes.\n",
            "Found 189 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    base_model = MobileNetV2(\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        include_top=False,\n",
        "        weights='imagenet'\n",
        "    )\n",
        "    base_model.trainable = hp.Boolean(\"fine_tune\", default=False)\n",
        "    model = keras.Sequential()\n",
        "    model.add(base_model)\n",
        "    model.add(layers.GlobalAveragePooling2D())\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Dense(\n",
        "        units=hp.Int(\"dense_units1\", min_value=64, max_value=512, step=64),\n",
        "        activation=\"relu\"\n",
        "    ))\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout1\", min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(layers.Dense(\n",
        "        units=hp.Int(\"dense_units2\", min_value=32, max_value=256, step=32),\n",
        "        activation=\"relu\"\n",
        "    ))\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"dropout2\", min_value=0.2, max_value=0.5, step=0.1)))\n",
        "    model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Float(\"learning_rate\", 1e-5, 1e-3, sampling=\"log\")\n",
        "        ),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "teedp3AkhQDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective=\"val_accuracy\",\n",
        "    max_trials=10,\n",
        "    directory=\"kt_dir\",\n",
        "    project_name=\"mobilenetv2_cleanliness\"\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    keras.callbacks.ReduceLROnPlateau(patience=2),\n",
        "]\n",
        "\n",
        "tuner.search(\n",
        "    train_gen,\n",
        "    epochs=20,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbc3Rmg5hWuq",
        "outputId": "f02d5485-00f1-4b7e-8e2c-b0f1c9aed399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 03m 20s]\n",
            "val_accuracy: 0.8042327761650085\n",
            "\n",
            "Best val_accuracy So Far: 0.9047619104385376\n",
            "Total elapsed time: 00h 48m 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(1)[0]\n",
        "best_model.save(\"/content/mobilenetv2_best_tuned.h5\")\n",
        "\n",
        "val_loss, val_acc = best_model.evaluate(val_gen)\n",
        "print(f\"Best validation accuracy: {val_acc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EoHf7Rrhds9",
        "outputId": "f48f4725-5b9d-4aa8-8d30-a9f734afe478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 223ms/step - accuracy: 0.9316 - loss: 0.2394\n",
            "Best validation accuracy: 0.905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wW8tPUrhgOT",
        "outputId": "ba4a8334-f3f6-429d-9928-0abba0560c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in kt_dir/mobilenetv2_cleanliness\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 04 summary\n",
            "Hyperparameters:\n",
            "fine_tune: False\n",
            "dense_units1: 384\n",
            "dropout1: 0.2\n",
            "dense_units2: 256\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 0.0005986673858497197\n",
            "Score: 0.9047619104385376\n",
            "\n",
            "Trial 00 summary\n",
            "Hyperparameters:\n",
            "fine_tune: False\n",
            "dense_units1: 192\n",
            "dropout1: 0.2\n",
            "dense_units2: 128\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 0.00026051698784545477\n",
            "Score: 0.8730158805847168\n",
            "\n",
            "Trial 07 summary\n",
            "Hyperparameters:\n",
            "fine_tune: False\n",
            "dense_units1: 384\n",
            "dropout1: 0.2\n",
            "dense_units2: 256\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 6.72349583281083e-05\n",
            "Score: 0.8359788656234741\n",
            "\n",
            "Trial 09 summary\n",
            "Hyperparameters:\n",
            "fine_tune: True\n",
            "dense_units1: 320\n",
            "dropout1: 0.2\n",
            "dense_units2: 192\n",
            "dropout2: 0.4\n",
            "learning_rate: 9.196308750140528e-05\n",
            "Score: 0.8042327761650085\n",
            "\n",
            "Trial 03 summary\n",
            "Hyperparameters:\n",
            "fine_tune: False\n",
            "dense_units1: 384\n",
            "dropout1: 0.30000000000000004\n",
            "dense_units2: 224\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 0.000154976703990679\n",
            "Score: 0.7936508059501648\n",
            "\n",
            "Trial 02 summary\n",
            "Hyperparameters:\n",
            "fine_tune: True\n",
            "dense_units1: 512\n",
            "dropout1: 0.30000000000000004\n",
            "dense_units2: 96\n",
            "dropout2: 0.2\n",
            "learning_rate: 1.2227914055837984e-05\n",
            "Score: 0.7513227462768555\n",
            "\n",
            "Trial 01 summary\n",
            "Hyperparameters:\n",
            "fine_tune: False\n",
            "dense_units1: 256\n",
            "dropout1: 0.30000000000000004\n",
            "dense_units2: 160\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 2.4792777118791422e-05\n",
            "Score: 0.7407407164573669\n",
            "\n",
            "Trial 06 summary\n",
            "Hyperparameters:\n",
            "fine_tune: True\n",
            "dense_units1: 448\n",
            "dropout1: 0.2\n",
            "dense_units2: 160\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 2.5886644352160877e-05\n",
            "Score: 0.6984127163887024\n",
            "\n",
            "Trial 05 summary\n",
            "Hyperparameters:\n",
            "fine_tune: True\n",
            "dense_units1: 320\n",
            "dropout1: 0.30000000000000004\n",
            "dense_units2: 32\n",
            "dropout2: 0.30000000000000004\n",
            "learning_rate: 4.0154681549124993e-05\n",
            "Score: 0.6878306865692139\n",
            "\n",
            "Trial 08 summary\n",
            "Hyperparameters:\n",
            "fine_tune: True\n",
            "dense_units1: 256\n",
            "dropout1: 0.30000000000000004\n",
            "dense_units2: 96\n",
            "dropout2: 0.4\n",
            "learning_rate: 6.474873450435775e-05\n",
            "Score: 0.6507936716079712\n"
          ]
        }
      ]
    }
  ]
}